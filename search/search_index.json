{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Nama : Nuril Adhimi Rachmatullah NIM : 180411100029 Studi : Teknik Informatika Kelas : Penambangan Data 5E Semester : 3 (tiga) Universitas Trunojoyo Madura","title":"Biodata"},{"location":"Mengukur Jarak/","text":"Pengertian \u00b6 Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkan. Mengukur Jarak Menggunakan Minkowski Distance \u00b6 Langkah-langkah mengukur jarak kali ini saya menggunakan Minkowski Distance . Minkowski Distance adalah matrik dalam ruang vektor normed yang dapat dianggap sebagai generalisasi dari Euclidean Distance dan Manhattan Distance. $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ diman mm adalah bilangan riel positif dan xixi dan $ y_i$ adalah dua vektor dalam runang dimensi nn Implementasi ukuran jarak Minkowski pada model clustering data atribut dilakukan normalisasi untuk menghindari dominasi dari atribut yang memiliki skala data besar. Langkah-Langkah Mengukur jarak: sebelumnya kita ambil data dari website https://archive.ics.uci.edu/ml/datasets/wholesale+customers Download datanya dan kita jalankan python , tulis script seperti di bawah ini digunakan untuk mengambil data 4 baris : import pandas as pd from scipy import stats df = pd . read_csv ( 'Wholesale customers data.csv' , nrows = 4 , sep = ';' ) df Hasil dari script di atas: Channel Region Fresh Milk Grocery Frozen Detergents_Paper Delicassen 0 2 3 12669 9656 7561 214 2674 1338 1 2 3 7057 9810 9568 1762 3293 1776 2 2 3 6353 8808 7684 2405 3516 7844 3 1 3 13265 1196 4221 6404 507 1788 Menghitung Jarak antar data: ```python import scipy.spatial.distance as minko import itertools def minkowski (x,y,data): return sum(x)+sum(y) dfvalues = df.values.tolist() data = [ [x[0],x[1],minko.minkowski(dfvalues[x[0]], dfvalues[x[1]], 1) ,minko.minkowski(dfvalues[x[0]], dfvalues[x[1]], 2)] for x in itertools.combinations(range(4),2) ] columns = ['x','y', 'Minkowski (m-1)', 'Minkowski (m-2)'] pd.DataFrame(data, coluns=columns) ``` Hasil dari script di atas: x y Minkowski (m-1) Minkowski (m-2) 0 0 1 10378.0 6206.256360 1 0 2 16826.0 9405.507429 2 0 3 21204.0 11238.189623 3 1 2 10524.0 6506.372107 4 1 3 27610.0 13062.954260 5 2 3 31052.0 13395.218401 Langkah di bawah ini Mengukur Jarak Antara Numerick python numerical=[0,3] categorical=[1,2,6,7] binary=[4,5,8] ordinal=[1,2] on def chordDist(v1,v2,jnis): jmlh=0 normv1=0 normv2=0 for x in range (len(jnis)): normv1=normv1+(int(df.values.tolist()[v1][jnis[x]])**2) normv2=normv2+(int(df.values.tolist()[v1][jnis[x]])**2) jmlh=jmlh+(int(df.values.tolist()[v1][jnis[x]])*int(df.values.tolist()[v2][jnis[x]])) return ((2-(2*jmlh/(normv1*normv2)))**0.5) Hasil dari script di atas: x y Jarak Numeric Ordinal Categorical Binary 0 2 0 1.41 0 0 0 0 3 0 1.41 0 0 0 1 2 0 1.41 0 0 0 1 3 0 1.41 0 0 0 2 3 0 1.41 0 0 0 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Menghitung Jarak Data"},{"location":"Mengukur Jarak/#pengertian","text":"Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkan.","title":"Pengertian"},{"location":"Mengukur Jarak/#mengukur-jarak-menggunakan-minkowski-distance","text":"Langkah-langkah mengukur jarak kali ini saya menggunakan Minkowski Distance . Minkowski Distance adalah matrik dalam ruang vektor normed yang dapat dianggap sebagai generalisasi dari Euclidean Distance dan Manhattan Distance. $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ diman mm adalah bilangan riel positif dan xixi dan $ y_i$ adalah dua vektor dalam runang dimensi nn Implementasi ukuran jarak Minkowski pada model clustering data atribut dilakukan normalisasi untuk menghindari dominasi dari atribut yang memiliki skala data besar. Langkah-Langkah Mengukur jarak: sebelumnya kita ambil data dari website https://archive.ics.uci.edu/ml/datasets/wholesale+customers Download datanya dan kita jalankan python , tulis script seperti di bawah ini digunakan untuk mengambil data 4 baris : import pandas as pd from scipy import stats df = pd . read_csv ( 'Wholesale customers data.csv' , nrows = 4 , sep = ';' ) df Hasil dari script di atas: Channel Region Fresh Milk Grocery Frozen Detergents_Paper Delicassen 0 2 3 12669 9656 7561 214 2674 1338 1 2 3 7057 9810 9568 1762 3293 1776 2 2 3 6353 8808 7684 2405 3516 7844 3 1 3 13265 1196 4221 6404 507 1788 Menghitung Jarak antar data: ```python import scipy.spatial.distance as minko import itertools def minkowski (x,y,data): return sum(x)+sum(y) dfvalues = df.values.tolist() data = [ [x[0],x[1],minko.minkowski(dfvalues[x[0]], dfvalues[x[1]], 1) ,minko.minkowski(dfvalues[x[0]], dfvalues[x[1]], 2)] for x in itertools.combinations(range(4),2) ] columns = ['x','y', 'Minkowski (m-1)', 'Minkowski (m-2)'] pd.DataFrame(data, coluns=columns) ``` Hasil dari script di atas: x y Minkowski (m-1) Minkowski (m-2) 0 0 1 10378.0 6206.256360 1 0 2 16826.0 9405.507429 2 0 3 21204.0 11238.189623 3 1 2 10524.0 6506.372107 4 1 3 27610.0 13062.954260 5 2 3 31052.0 13395.218401 Langkah di bawah ini Mengukur Jarak Antara Numerick python numerical=[0,3] categorical=[1,2,6,7] binary=[4,5,8] ordinal=[1,2] on def chordDist(v1,v2,jnis): jmlh=0 normv1=0 normv2=0 for x in range (len(jnis)): normv1=normv1+(int(df.values.tolist()[v1][jnis[x]])**2) normv2=normv2+(int(df.values.tolist()[v1][jnis[x]])**2) jmlh=jmlh+(int(df.values.tolist()[v1][jnis[x]])*int(df.values.tolist()[v2][jnis[x]])) return ((2-(2*jmlh/(normv1*normv2)))**0.5) Hasil dari script di atas: x y Jarak Numeric Ordinal Categorical Binary 0 2 0 1.41 0 0 0 0 3 0 1.41 0 0 0 1 2 0 1.41 0 0 0 1 3 0 1.41 0 0 0 2 3 0 1.41 0 0 0 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Mengukur Jarak Menggunakan Minkowski Distance"},{"location":"fuzzy_c_mean/","text":"Fuzzy C-Mean Clustering \u00b6 Fuzzy C-Means (FCM) adalah salah satu teknik peng-cluster-an data yang mana keberadaan tiap-tiap titik data dalam suatu cluster ditentukan oleh derajat keanggotaannya. Teknik ini pertama kali diperkenalkan oleh Jim Bezdek pada tahun 1981 (Kusumadewi, 2006). Fuzzy Cluster Means (FCM) merupakan algoritma yang digunakan untuk melakukan clustering data sesuai berdasarkan keberadaan tiap-tiap titik data sesuai dengan derajat keanggotaannya (Ahmadi dan Hartati, 2013). Berikut adalah algoritma clustering FCM: import pandas as pd import random import numpy as np from IPython.display import HTML , display from tabulate import tabulate from math import log from sklearn.feature_selection import mutual_info_classif def table ( df ): display ( HTML ( tabulate ( df , tablefmt = 'html' , headers = 'keys' , showindex = False ))) Data = pd . read_csv ( 'Wholesale customers data.csv' , sep = ';' ) Data = Data [[ 'Channel' , 'Region' , 'Fresh' , 'Milk' , 'Grocery' , 'Frozen' , 'Detergents_Paper' , 'Delicassen' ]] . sample ( 6 , random_state = 42 ) D = Data . values print ( \"Table (D) >>\" ) table ( D ) Table (D) >> 0 1 2 3 4 5 6 7 1 1 5909 23527 13699 10155 830 3636 1 3 10766 1175 2067 2096 301 167 2 3 27380 7184 12311 2809 4621 1022 1 1 31614 489 1495 3242 111 615 1 2 542 899 1664 414 88 522 1 3 6022 3354 3261 2507 212 686 n , m , c , w , T , e , P0 , t = * D . shape , 3 , 2 , 10 , 0.1 , 0 , 1 print ( \"Variables >>\" ) print ( \" n = %d \\n m = %d \\n c = %d \\n w = %d \\n T = %d \\n e = %f \\n P0 = %d \\n t = %d \" % ( n , m , c , w , T , e , P0 , t )) Variables >> n = 6 m = 8 c = 3 w = 2 T = 10 e = 0.100000 P0 = 0 t = 1 random . seed ( 42 ) U = np . array ([[ random . uniform ( 0 , 1 ) for _ in range ( c )] for _ in range ( n )]) print ( \"U >> \\n \" ) print ( U ) U >> [[0.6394268 0.02501076 0.27502932] [0.22321074 0.73647121 0.67669949] [0.89217957 0.08693883 0.42192182] [0.02979722 0.21863797 0.50535529] [0.02653597 0.19883765 0.64988444] [0.54494148 0.22044062 0.58926568]] def cluster ( U , D , x , y ): return sum ([ U [ i , y ] ** w * D [ i , x ] for i in range ( n )]) / sum ([ U [ i , y ] ** w for i in range ( n )]) V = np . array ([[ cluster ( U , D , x , y ) for x in range ( m )] for y in range ( c )]) print ( \"V >> \\n \" ) print ( V ) V >> [[1.51247128e+00 2.47192972e+00 1.71019345e+04 1.05543949e+04 1.06064976e+04 4.66128920e+03 2.63690715e+03 1.61797605e+03] [1.01100988e+00 2.80132372e+00 1.14715629e+04 1.35210251e+03 2.21186263e+03 2.12321601e+03 3.17248073e+02 2.67951201e+02] [1.10251252e+00 2.37554317e+00 1.18883782e+04 3.03230522e+03 3.68042112e+03 2.36176246e+03 6.69353943e+02 6.61754289e+02]] def objective ( V , U , D ): return sum ([ sum ([ sum ([( D [ i , j ] - V [ k , j ]) ** 2 for j in range ( m )]) * ( U [ i , k ] ** w ) for k in range ( c )]) for i in range ( n )]) Pt = objective ( V , U , D ) print ( \"Pt >> \\n \" ) print ( Pt ) Pt >> 640674712.1622174 def converge ( V , D , i , k ): return ( sum ([( D [ i , j ] - V [ k , j ]) ** 2 for j in range ( m )]) ** ( - 1 / ( w - 1 ))) / sum ([ sum ([( D [ i , j ] - V [ k , j ]) ** 2 for j in range ( m )]) ** ( - 1 / ( w - 1 )) for k in range ( c )]) print ( \"U >> \\n \" ) np . array ([[ converge ( V , D , i , k ) for k in range ( c )] for i in range ( n )]) U >> array([[0.49737566, 0.23186403, 0.27076031], [0.00242697, 0.93030465, 0.06726838], [0.59544397, 0.18596743, 0.21858859], [0.33363563, 0.33031953, 0.33604483], [0.12209125, 0.46967067, 0.40823809], [0.06802974, 0.46455851, 0.46741174]]) def iterate ( U ): V = np . array ([[ cluster ( U , D , x , y ) for x in range ( m )] for y in range ( c )]) return np . array ([[ converge ( V , D , i , k ) for k in range ( c )] for i in range ( n )]), objective ( V , U , D ) def fuzzyCM ( U ): #U = np.array([[random.uniform(0, 1) for _ in range(c)] for _ in range(n)]) U , P2 , P , t = * iterate ( U ), 0 , 1 while abs ( P2 - P ) > e and t < T : U , P2 , P , t = * iterate ( U ), P2 , t + 1 return U , t FuzzyResult , FuzzyIters = fuzzyCM ( U ) print ( \"Iterating %d times, fuzzy result >> \\n \" % FuzzyIters ) print ( FuzzyResult ) Iterating 10 times, fuzzy result >> [[2.90393097e-05 4.55125640e-05 9.99925448e-01] [6.04990406e-02 9.07517383e-01 3.19835766e-02] [8.63809090e-01 7.69094440e-02 5.92814660e-02] [9.08087538e-01 6.18887571e-02 3.00237046e-02] [3.23743920e-02 9.31095468e-01 3.65301405e-02] [6.31554532e-03 9.87455055e-01 6.22940008e-03]] table ( DataFrame ([ D [ i ] . tolist () + [ np . argmax ( FuzzyResult [ i ] . tolist ())] for i in range ( n )], columns = Data . columns . tolist () + [ \"Cluster Index\" ])) Channel Region Fresh Milk Grocery Frozen Detergents_Paper Delicassen Cluster Index 1 1 5909 23527 13699 10155 830 3636 2 1 3 10766 1175 2067 2096 301 167 1 2 3 27380 7184 12311 2809 4621 1022 0 1 1 31614 489 1495 3242 111 615 0 1 2 542 899 1664 414 88 522 1 1 3 6022 3354 3261 2507 212 686 1","title":"Implementasi Fuzzy C-Means"},{"location":"fuzzy_c_mean/#fuzzy-c-mean-clustering","text":"Fuzzy C-Means (FCM) adalah salah satu teknik peng-cluster-an data yang mana keberadaan tiap-tiap titik data dalam suatu cluster ditentukan oleh derajat keanggotaannya. Teknik ini pertama kali diperkenalkan oleh Jim Bezdek pada tahun 1981 (Kusumadewi, 2006). Fuzzy Cluster Means (FCM) merupakan algoritma yang digunakan untuk melakukan clustering data sesuai berdasarkan keberadaan tiap-tiap titik data sesuai dengan derajat keanggotaannya (Ahmadi dan Hartati, 2013). Berikut adalah algoritma clustering FCM: import pandas as pd import random import numpy as np from IPython.display import HTML , display from tabulate import tabulate from math import log from sklearn.feature_selection import mutual_info_classif def table ( df ): display ( HTML ( tabulate ( df , tablefmt = 'html' , headers = 'keys' , showindex = False ))) Data = pd . read_csv ( 'Wholesale customers data.csv' , sep = ';' ) Data = Data [[ 'Channel' , 'Region' , 'Fresh' , 'Milk' , 'Grocery' , 'Frozen' , 'Detergents_Paper' , 'Delicassen' ]] . sample ( 6 , random_state = 42 ) D = Data . values print ( \"Table (D) >>\" ) table ( D ) Table (D) >> 0 1 2 3 4 5 6 7 1 1 5909 23527 13699 10155 830 3636 1 3 10766 1175 2067 2096 301 167 2 3 27380 7184 12311 2809 4621 1022 1 1 31614 489 1495 3242 111 615 1 2 542 899 1664 414 88 522 1 3 6022 3354 3261 2507 212 686 n , m , c , w , T , e , P0 , t = * D . shape , 3 , 2 , 10 , 0.1 , 0 , 1 print ( \"Variables >>\" ) print ( \" n = %d \\n m = %d \\n c = %d \\n w = %d \\n T = %d \\n e = %f \\n P0 = %d \\n t = %d \" % ( n , m , c , w , T , e , P0 , t )) Variables >> n = 6 m = 8 c = 3 w = 2 T = 10 e = 0.100000 P0 = 0 t = 1 random . seed ( 42 ) U = np . array ([[ random . uniform ( 0 , 1 ) for _ in range ( c )] for _ in range ( n )]) print ( \"U >> \\n \" ) print ( U ) U >> [[0.6394268 0.02501076 0.27502932] [0.22321074 0.73647121 0.67669949] [0.89217957 0.08693883 0.42192182] [0.02979722 0.21863797 0.50535529] [0.02653597 0.19883765 0.64988444] [0.54494148 0.22044062 0.58926568]] def cluster ( U , D , x , y ): return sum ([ U [ i , y ] ** w * D [ i , x ] for i in range ( n )]) / sum ([ U [ i , y ] ** w for i in range ( n )]) V = np . array ([[ cluster ( U , D , x , y ) for x in range ( m )] for y in range ( c )]) print ( \"V >> \\n \" ) print ( V ) V >> [[1.51247128e+00 2.47192972e+00 1.71019345e+04 1.05543949e+04 1.06064976e+04 4.66128920e+03 2.63690715e+03 1.61797605e+03] [1.01100988e+00 2.80132372e+00 1.14715629e+04 1.35210251e+03 2.21186263e+03 2.12321601e+03 3.17248073e+02 2.67951201e+02] [1.10251252e+00 2.37554317e+00 1.18883782e+04 3.03230522e+03 3.68042112e+03 2.36176246e+03 6.69353943e+02 6.61754289e+02]] def objective ( V , U , D ): return sum ([ sum ([ sum ([( D [ i , j ] - V [ k , j ]) ** 2 for j in range ( m )]) * ( U [ i , k ] ** w ) for k in range ( c )]) for i in range ( n )]) Pt = objective ( V , U , D ) print ( \"Pt >> \\n \" ) print ( Pt ) Pt >> 640674712.1622174 def converge ( V , D , i , k ): return ( sum ([( D [ i , j ] - V [ k , j ]) ** 2 for j in range ( m )]) ** ( - 1 / ( w - 1 ))) / sum ([ sum ([( D [ i , j ] - V [ k , j ]) ** 2 for j in range ( m )]) ** ( - 1 / ( w - 1 )) for k in range ( c )]) print ( \"U >> \\n \" ) np . array ([[ converge ( V , D , i , k ) for k in range ( c )] for i in range ( n )]) U >> array([[0.49737566, 0.23186403, 0.27076031], [0.00242697, 0.93030465, 0.06726838], [0.59544397, 0.18596743, 0.21858859], [0.33363563, 0.33031953, 0.33604483], [0.12209125, 0.46967067, 0.40823809], [0.06802974, 0.46455851, 0.46741174]]) def iterate ( U ): V = np . array ([[ cluster ( U , D , x , y ) for x in range ( m )] for y in range ( c )]) return np . array ([[ converge ( V , D , i , k ) for k in range ( c )] for i in range ( n )]), objective ( V , U , D ) def fuzzyCM ( U ): #U = np.array([[random.uniform(0, 1) for _ in range(c)] for _ in range(n)]) U , P2 , P , t = * iterate ( U ), 0 , 1 while abs ( P2 - P ) > e and t < T : U , P2 , P , t = * iterate ( U ), P2 , t + 1 return U , t FuzzyResult , FuzzyIters = fuzzyCM ( U ) print ( \"Iterating %d times, fuzzy result >> \\n \" % FuzzyIters ) print ( FuzzyResult ) Iterating 10 times, fuzzy result >> [[2.90393097e-05 4.55125640e-05 9.99925448e-01] [6.04990406e-02 9.07517383e-01 3.19835766e-02] [8.63809090e-01 7.69094440e-02 5.92814660e-02] [9.08087538e-01 6.18887571e-02 3.00237046e-02] [3.23743920e-02 9.31095468e-01 3.65301405e-02] [6.31554532e-03 9.87455055e-01 6.22940008e-03]] table ( DataFrame ([ D [ i ] . tolist () + [ np . argmax ( FuzzyResult [ i ] . tolist ())] for i in range ( n )], columns = Data . columns . tolist () + [ \"Cluster Index\" ])) Channel Region Fresh Milk Grocery Frozen Detergents_Paper Delicassen Cluster Index 1 1 5909 23527 13699 10155 830 3636 2 1 3 10766 1175 2067 2096 301 167 1 2 3 27380 7184 12311 2809 4621 1022 0 1 1 31614 489 1495 3242 111 615 0 1 2 542 899 1664 414 88 522 1 1 3 6022 3354 3261 2507 212 686 1","title":"Fuzzy C-Mean Clustering"},{"location":"knn/","text":"W-KNN (Weighted K-Nearest Neighbour) \u00b6 Mengambil Sample data: sepal_length sepal_width petal_length petal_width species 4 3,5 4,2 1,7 versicolor Data iris : sepal_length as A sepal_width as B petal_length as C petal_width as D species 6,9 3,1 5,1 2,3 virginica 6,7 3 5 1,7 versicolor 6,9 3,1 4,9 1,5 versicolor 6,7 3 5,2 2,3 virginica 6,7 3,1 4,7 1,5 versicolor 6,5 3,2 5,1 2 virginica 6,9 3,1 5,4 2,1 virginica 7 3,2 4,7 1,4 versicolor 6,5 3 5,2 2 virginica 6,8 2,8 4,8 1,4 versicolor 6,8 3 5,5 2,1 virginica 6,5 2,8 4,6 1,5 versicolor 6,7 3,1 4,4 1,4 versicolor 6,3 2,7 4,9 1,8 virginica 6,6 3 4,4 1,4 versicolor 6,6 2,9 4,6 1,3 versicolor 6,4 2,7 5,3 1,9 virginica 6,2 2,8 4,8 1,8 virginica 6,4 3,2 4,5 1,5 versicolor 6,4 3,2 5,3 2,3 virginica 6,3 3,3 4,7 1,6 versicolor 6,5 3 5,5 1,8 virginica 6,3 2,5 5 1,9 virginica 6,1 3 4,9 1,8 virginica 6,3 2,8 5,1 1,5 virginica 6,7 3,1 5,6 2,4 virginica 6,4 3,1 5,5 1,8 virginica 6,9 3,2 5,7 2,3 virginica 6,3 2,5 4,9 1,5 versicolor 6,7 3,3 5,7 2,1 virginica 6 3 4,8 1,8 virginica 6,4 2,8 5,6 2,1 virginica 6,4 2,8 5,6 2,2 virginica 6,4 2,9 4,3 1,3 versicolor 6,3 2,9 5,6 1,8 virginica 6,1 2,9 4,7 1,4 versicolor 7,2 3 5,8 1,6 virginica 6,1 3 4,6 1,4 versicolor 7,1 3 5,9 2,1 virginica 6,7 3,3 5,7 2,5 virginica 6,2 3,4 5,4 2,3 virginica 5,9 3,2 4,8 1,8 versicolor 6,5 3 5,8 2,2 virginica 5,9 3 5,1 1,8 virginica 6 2,7 5,1 1,6 versicolor 6 2,9 4,5 1,5 versicolor 6,7 2,5 5,8 1,8 virginica 6,8 3,2 5,9 2,3 virginica 6,2 2,9 4,3 1,3 versicolor 6 3,4 4,5 1,6 versicolor 6,3 3,4 5,6 2,4 virginica 6,1 2,8 4,7 1,2 versicolor 7,2 3,2 6 1,8 virginica 6,2 2,2 4,5 1,5 versicolor 6,3 2,3 4,4 1,3 versicolor 5,8 2,7 5,1 1,9 virginica 5,8 2,7 5,1 1,9 virginica 5,8 2,8 5,1 2,4 virginica 5,9 3 4,2 1,5 versicolor 7,4 2,8 6,1 1,9 virginica 6 2,2 5 1,5 virginica 6,1 2,6 5,6 1,4 virginica 5,7 2,5 5 2 virginica 6,1 2,8 4 1,3 versicolor 5,6 2,8 4,9 2 virginica 7,7 3 6,1 2,3 virginica 6,3 3,3 6 2,5 virginica 5,6 3 4,5 1,5 versicolor 5,7 2,8 4,5 1,3 versicolor 7,2 3,6 6,1 2,5 virginica 7,3 2,9 6,3 1,8 virginica 5,7 2,9 4,2 1,3 versicolor 5,7 3 4,2 1,2 versicolor 5,7 2,8 4,1 1,3 versicolor 5,8 2,6 4 1,2 versicolor 5,4 3 4,5 1,5 versicolor 5,6 2,7 4,2 1,3 versicolor 5,6 3 4,1 1,3 versicolor 5,8 2,7 3,9 1,2 versicolor 5,8 2,7 4,1 1 versicolor 5,5 2,6 4,4 1,2 versicolor 6 2,2 4 1 versicolor 7,6 3 6,6 2,1 virginica 5,5 2,5 4 1,3 versicolor 5,6 2,5 3,9 1,1 versicolor 5,5 2,3 4 1,3 versicolor 5,6 2,9 3,6 1,3 versicolor 7,9 3,8 6,4 2 virginica 7,7 2,8 6,7 2 virginica 5,5 2,4 3,8 1,1 versicolor 5,2 2,7 3,9 1,4 versicolor 5,7 2,6 3,5 1 versicolor 7,7 3,8 6,7 2,2 virginica 5,5 2,4 3,7 1 versicolor 4,9 2,5 4,5 1,7 virginica 7,7 2,6 6,9 2,3 virginica 5 2 3,5 1 versicolor 5 2,3 3,3 1 versicolor 5,1 2,5 3 1,1 versicolor 4,9 2,4 3,3 1 versicolor 5,7 3,8 1,7 0,3 setosa 5,1 3,8 1,9 0,4 setosa 5,4 3,9 1,7 0,4 setosa 5,1 3,3 1,7 0,5 setosa 5,4 3,4 1,7 0,2 setosa 5,4 3,4 1,5 0,4 setosa 5 3,5 1,6 0,6 setosa 4,8 3,4 1,9 0,2 setosa 5 3,4 1,6 0,4 setosa 5,7 4,4 1,5 0,4 setosa 5,4 3,7 1,5 0,2 setosa 5 3 1,6 0,2 setosa 5,3 3,7 1,5 0,2 setosa 5,1 3,7 1,5 0,4 setosa 5,2 3,5 1,5 0,2 setosa 5,1 3,8 1,6 0,2 setosa 5,1 3,4 1,5 0,2 setosa 5,5 3,5 1,3 0,2 setosa 5,1 3,8 1,5 0,3 setosa 5,4 3,9 1,3 0,4 setosa 5,2 3,4 1,4 0,2 setosa 5 3,4 1,5 0,2 setosa 5,1 3,5 1,4 0,3 setosa 4,8 3,1 1,6 0,2 setosa 4,8 3,4 1,6 0,2 setosa 5,5 4,2 1,4 0,2 setosa 5,8 4 1,2 0,2 setosa 5,1 3,5 1,4 0,2 setosa 4,7 3,2 1,6 0,2 setosa 5 3,3 1,4 0,2 setosa 4,9 3,1 1,5 0,1 setosa 4,9 3,1 1,5 0,1 setosa 4,9 3,1 1,5 0,1 setosa 5,2 4,1 1,5 0,1 setosa 5 3,6 1,4 0,2 setosa 4,9 3 1,4 0,2 setosa 4,8 3 1,4 0,3 setosa 5 3,5 1,3 0,3 setosa 4,6 3,1 1,5 0,2 setosa 4,8 3 1,4 0,1 setosa 5 3,2 1,2 0,2 setosa 4,6 3,4 1,4 0,3 setosa 4,6 3,2 1,4 0,2 setosa 4,7 3,2 1,3 0,2 setosa 4,4 2,9 1,4 0,2 setosa 4,5 2,3 1,3 0,3 setosa 4,4 3 1,3 0,2 setosa 4,4 3,2 1,3 0,2 setosa 4,6 3,6 1 0,2 setosa 4,3 3 1,1 0,1 setosa Menghitung jarak dengan sample data : (A-S1)^2 (B-S2)^2 (C-S3)^2 (D-S4)^2 SQRT(D) 8,4 0,2 0,8 0,4 3,1 7,3 0,3 0,6 0,0 2,9 8,4 0,2 0,5 0,0 3,0 7,3 0,3 1,0 0,4 3,0 7,3 0,2 0,3 0,0 2,8 6,3 0,1 0,8 0,1 2,7 8,4 0,2 1,4 0,2 3,2 9,0 0,1 0,3 0,1 3,1 6,3 0,3 1,0 0,1 2,8 7,8 0,5 0,4 0,1 3,0 7,8 0,3 1,7 0,2 3,2 6,3 0,5 0,2 0,0 2,6 7,3 0,2 0,0 0,1 2,8 5,3 0,6 0,5 0,0 2,5 6,8 0,3 0,0 0,1 2,7 6,8 0,4 0,2 0,2 2,7 5,8 0,6 1,2 0,0 2,8 4,8 0,5 0,4 0,0 2,4 5,8 0,1 0,1 0,0 2,4 5,8 0,1 1,2 0,4 2,7 5,3 0,0 0,3 0,0 2,4 6,3 0,3 1,7 0,0 2,9 5,3 1,0 0,6 0,0 2,6 4,4 0,3 0,5 0,0 2,3 5,3 0,5 0,8 0,0 2,6 7,3 0,2 2,0 0,5 3,1 5,8 0,2 1,7 0,0 2,8 8,4 0,1 2,3 0,4 3,3 5,3 1,0 0,5 0,0 2,6 7,3 0,0 2,3 0,2 3,1 4,0 0,3 0,4 0,0 2,1 5,8 0,5 2,0 0,2 2,9 5,8 0,5 2,0 0,3 2,9 5,8 0,4 0,0 0,2 2,5 5,3 0,4 2,0 0,0 2,8 4,4 0,4 0,3 0,1 2,3 10,2 0,3 2,6 0,0 3,6 4,4 0,3 0,2 0,1 2,2 9,6 0,3 2,9 0,2 3,6 7,3 0,0 2,3 0,6 3,2 4,8 0,0 1,4 0,4 2,6 3,6 0,1 0,4 0,0 2,0 6,3 0,3 2,6 0,3 3,1 3,6 0,3 0,8 0,0 2,2 4,0 0,6 0,8 0,0 2,3 4,0 0,4 0,1 0,0 2,1 7,3 1,0 2,6 0,0 3,3 7,8 0,1 2,9 0,4 3,3 4,8 0,4 0,0 0,2 2,3 4,0 0,0 0,1 0,0 2,0 5,3 0,0 2,0 0,5 2,8 4,4 0,5 0,3 0,3 2,3 10,2 0,1 3,2 0,0 3,7 4,8 1,7 0,1 0,0 2,6 5,3 1,4 0,0 0,2 2,6 3,2 0,6 0,8 0,0 2,2 3,2 0,6 0,8 0,0 2,2 3,2 0,5 0,8 0,5 2,2 3,6 0,3 0,0 0,0 2,0 11,6 0,5 3,6 0,0 4,0 4,0 1,7 0,6 0,0 2,5 4,4 0,8 2,0 0,1 2,7 2,9 1,0 0,6 0,1 2,1 4,4 0,5 0,0 0,2 2,3 2,6 0,5 0,5 0,1 1,9 13,7 0,3 3,6 0,4 4,2 5,3 0,0 3,2 0,6 3,0 2,6 0,3 0,1 0,0 1,7 2,9 0,5 0,1 0,2 1,9 10,2 0,0 3,6 0,6 3,8 10,9 0,4 4,4 0,0 4,0 2,9 0,4 0,0 0,2 1,8 2,9 0,3 0,0 0,3 1,8 2,9 0,5 0,0 0,2 1,9 3,2 0,8 0,0 0,3 2,1 2,0 0,3 0,1 0,0 1,5 2,6 0,6 0,0 0,2 1,8 2,6 0,3 0,0 0,2 1,7 3,2 0,6 0,1 0,3 2,1 3,2 0,6 0,0 0,5 2,1 2,3 0,8 0,0 0,3 1,8 4,0 1,7 0,0 0,5 2,5 13,0 0,3 5,8 0,2 4,4 2,3 1,0 0,0 0,2 1,9 2,6 1,0 0,1 0,4 2,0 2,3 1,4 0,0 0,2 2,0 2,6 0,4 0,4 0,2 1,9 15,2 0,1 4,8 0,1 4,5 13,7 0,5 6,3 0,1 4,5 2,3 1,2 0,2 0,4 2,0 1,4 0,6 0,1 0,1 1,5 2,9 0,8 0,5 0,5 2,2 13,7 0,1 6,3 0,3 4,5 2,3 1,2 0,3 0,5 2,0 0,8 1,0 0,1 0,0 1,4 13,7 0,8 7,3 0,4 4,7 1,0 2,3 0,5 0,5 2,1 1,0 1,4 0,8 0,5 1,9 1,2 1,0 1,4 0,4 2,0 0,8 1,2 0,8 0,5 1,8 2,9 0,1 6,3 2,0 3,3 1,2 0,1 5,3 1,7 2,9 2,0 0,2 6,3 1,7 3,2 1,2 0,0 6,3 1,4 3,0 2,0 0,0 6,3 2,3 3,2 2,0 0,0 7,3 1,7 3,3 1,0 0,0 6,8 1,2 3,0 0,6 0,0 5,3 2,3 2,9 1,0 0,0 6,8 1,7 3,1 2,9 0,8 7,3 1,7 3,6 2,0 0,0 7,3 2,3 3,4 1,0 0,3 6,8 2,3 3,2 1,7 0,0 7,3 2,3 3,4 1,2 0,0 7,3 1,7 3,2 1,4 0,0 7,3 2,3 3,3 1,2 0,1 6,8 2,3 3,2 1,2 0,0 7,3 2,3 3,3 2,3 0,0 8,4 2,3 3,6 1,2 0,1 7,3 2,0 3,2 2,0 0,2 8,4 1,7 3,5 1,4 0,0 7,8 2,3 3,4 1,0 0,0 7,3 2,3 3,2 1,2 0,0 7,8 2,0 3,3 0,6 0,2 6,8 2,3 3,1 0,6 0,0 6,8 2,3 3,1 2,3 0,5 7,8 2,3 3,6 3,2 0,3 9,0 2,3 3,8 1,2 0,0 7,8 2,3 3,4 0,5 0,1 6,8 2,3 3,1 1,0 0,0 7,8 2,3 3,3 0,8 0,2 7,3 2,6 3,3 0,8 0,2 7,3 2,6 3,3 0,8 0,2 7,3 2,6 3,3 1,4 0,4 7,3 2,6 3,4 1,0 0,0 7,8 2,3 3,3 0,8 0,3 7,8 2,3 3,3 0,6 0,3 7,8 2,0 3,3 1,0 0,0 8,4 2,0 3,4 0,4 0,2 7,3 2,3 3,2 0,6 0,3 7,8 2,6 3,4 1,0 0,1 9,0 2,3 3,5 0,4 0,0 7,8 2,0 3,2 0,4 0,1 7,8 2,3 3,2 0,5 0,1 8,4 2,3 3,4 0,2 0,4 7,8 2,3 3,3 0,3 1,4 8,4 2,0 3,5 0,2 0,3 8,4 2,3 3,3 0,2 0,1 8,4 2,3 3,3 0,4 0,0 10,2 2,3 3,6 0,1 0,3 9,6 2,6 3,5 Mencari data tertinggi K = 5: sepal_length as A sepal_width as B petal_length as C petal_width as D species (A-S1)^2 (B-S2)^2 (C-S3)^2 (D-S4)^2 SQRT(D) 5,6 3 4,5 1,5 versicolor 2,6 0,3 0,1 0,0 1,7 5,4 3 4,5 1,5 versicolor 2,0 0,3 0,1 0,0 1,5 5,6 3 4,1 1,3 versicolor 2,6 0,3 0,0 0,2 1,7 5,2 2,7 3,9 1,4 versicolor 1,4 0,6 0,1 0,1 1,5 4,9 2,5 4,5 1,7 virginica 0,8 1,0 0,1 0,0 1,4 Menghitung berat antar variasi dengan 1/jaraknya : D 1/D Setosa versicolor virginica 1,4 0,725476 0 0 0,725476 1,5 0,65372 0 0,65372 0 1,5 0,66519 0 0,66519 0 1,7 0,583212 0 0,583212 0 1,7 0,579284 0 0,579284 0 sum 0 2,481407 0,725476 Jadi Nilai terbesar adalah : class = versicolor","title":"Metode KNN"},{"location":"knn/#w-knn-weighted-k-nearest-neighbour","text":"Mengambil Sample data: sepal_length sepal_width petal_length petal_width species 4 3,5 4,2 1,7 versicolor Data iris : sepal_length as A sepal_width as B petal_length as C petal_width as D species 6,9 3,1 5,1 2,3 virginica 6,7 3 5 1,7 versicolor 6,9 3,1 4,9 1,5 versicolor 6,7 3 5,2 2,3 virginica 6,7 3,1 4,7 1,5 versicolor 6,5 3,2 5,1 2 virginica 6,9 3,1 5,4 2,1 virginica 7 3,2 4,7 1,4 versicolor 6,5 3 5,2 2 virginica 6,8 2,8 4,8 1,4 versicolor 6,8 3 5,5 2,1 virginica 6,5 2,8 4,6 1,5 versicolor 6,7 3,1 4,4 1,4 versicolor 6,3 2,7 4,9 1,8 virginica 6,6 3 4,4 1,4 versicolor 6,6 2,9 4,6 1,3 versicolor 6,4 2,7 5,3 1,9 virginica 6,2 2,8 4,8 1,8 virginica 6,4 3,2 4,5 1,5 versicolor 6,4 3,2 5,3 2,3 virginica 6,3 3,3 4,7 1,6 versicolor 6,5 3 5,5 1,8 virginica 6,3 2,5 5 1,9 virginica 6,1 3 4,9 1,8 virginica 6,3 2,8 5,1 1,5 virginica 6,7 3,1 5,6 2,4 virginica 6,4 3,1 5,5 1,8 virginica 6,9 3,2 5,7 2,3 virginica 6,3 2,5 4,9 1,5 versicolor 6,7 3,3 5,7 2,1 virginica 6 3 4,8 1,8 virginica 6,4 2,8 5,6 2,1 virginica 6,4 2,8 5,6 2,2 virginica 6,4 2,9 4,3 1,3 versicolor 6,3 2,9 5,6 1,8 virginica 6,1 2,9 4,7 1,4 versicolor 7,2 3 5,8 1,6 virginica 6,1 3 4,6 1,4 versicolor 7,1 3 5,9 2,1 virginica 6,7 3,3 5,7 2,5 virginica 6,2 3,4 5,4 2,3 virginica 5,9 3,2 4,8 1,8 versicolor 6,5 3 5,8 2,2 virginica 5,9 3 5,1 1,8 virginica 6 2,7 5,1 1,6 versicolor 6 2,9 4,5 1,5 versicolor 6,7 2,5 5,8 1,8 virginica 6,8 3,2 5,9 2,3 virginica 6,2 2,9 4,3 1,3 versicolor 6 3,4 4,5 1,6 versicolor 6,3 3,4 5,6 2,4 virginica 6,1 2,8 4,7 1,2 versicolor 7,2 3,2 6 1,8 virginica 6,2 2,2 4,5 1,5 versicolor 6,3 2,3 4,4 1,3 versicolor 5,8 2,7 5,1 1,9 virginica 5,8 2,7 5,1 1,9 virginica 5,8 2,8 5,1 2,4 virginica 5,9 3 4,2 1,5 versicolor 7,4 2,8 6,1 1,9 virginica 6 2,2 5 1,5 virginica 6,1 2,6 5,6 1,4 virginica 5,7 2,5 5 2 virginica 6,1 2,8 4 1,3 versicolor 5,6 2,8 4,9 2 virginica 7,7 3 6,1 2,3 virginica 6,3 3,3 6 2,5 virginica 5,6 3 4,5 1,5 versicolor 5,7 2,8 4,5 1,3 versicolor 7,2 3,6 6,1 2,5 virginica 7,3 2,9 6,3 1,8 virginica 5,7 2,9 4,2 1,3 versicolor 5,7 3 4,2 1,2 versicolor 5,7 2,8 4,1 1,3 versicolor 5,8 2,6 4 1,2 versicolor 5,4 3 4,5 1,5 versicolor 5,6 2,7 4,2 1,3 versicolor 5,6 3 4,1 1,3 versicolor 5,8 2,7 3,9 1,2 versicolor 5,8 2,7 4,1 1 versicolor 5,5 2,6 4,4 1,2 versicolor 6 2,2 4 1 versicolor 7,6 3 6,6 2,1 virginica 5,5 2,5 4 1,3 versicolor 5,6 2,5 3,9 1,1 versicolor 5,5 2,3 4 1,3 versicolor 5,6 2,9 3,6 1,3 versicolor 7,9 3,8 6,4 2 virginica 7,7 2,8 6,7 2 virginica 5,5 2,4 3,8 1,1 versicolor 5,2 2,7 3,9 1,4 versicolor 5,7 2,6 3,5 1 versicolor 7,7 3,8 6,7 2,2 virginica 5,5 2,4 3,7 1 versicolor 4,9 2,5 4,5 1,7 virginica 7,7 2,6 6,9 2,3 virginica 5 2 3,5 1 versicolor 5 2,3 3,3 1 versicolor 5,1 2,5 3 1,1 versicolor 4,9 2,4 3,3 1 versicolor 5,7 3,8 1,7 0,3 setosa 5,1 3,8 1,9 0,4 setosa 5,4 3,9 1,7 0,4 setosa 5,1 3,3 1,7 0,5 setosa 5,4 3,4 1,7 0,2 setosa 5,4 3,4 1,5 0,4 setosa 5 3,5 1,6 0,6 setosa 4,8 3,4 1,9 0,2 setosa 5 3,4 1,6 0,4 setosa 5,7 4,4 1,5 0,4 setosa 5,4 3,7 1,5 0,2 setosa 5 3 1,6 0,2 setosa 5,3 3,7 1,5 0,2 setosa 5,1 3,7 1,5 0,4 setosa 5,2 3,5 1,5 0,2 setosa 5,1 3,8 1,6 0,2 setosa 5,1 3,4 1,5 0,2 setosa 5,5 3,5 1,3 0,2 setosa 5,1 3,8 1,5 0,3 setosa 5,4 3,9 1,3 0,4 setosa 5,2 3,4 1,4 0,2 setosa 5 3,4 1,5 0,2 setosa 5,1 3,5 1,4 0,3 setosa 4,8 3,1 1,6 0,2 setosa 4,8 3,4 1,6 0,2 setosa 5,5 4,2 1,4 0,2 setosa 5,8 4 1,2 0,2 setosa 5,1 3,5 1,4 0,2 setosa 4,7 3,2 1,6 0,2 setosa 5 3,3 1,4 0,2 setosa 4,9 3,1 1,5 0,1 setosa 4,9 3,1 1,5 0,1 setosa 4,9 3,1 1,5 0,1 setosa 5,2 4,1 1,5 0,1 setosa 5 3,6 1,4 0,2 setosa 4,9 3 1,4 0,2 setosa 4,8 3 1,4 0,3 setosa 5 3,5 1,3 0,3 setosa 4,6 3,1 1,5 0,2 setosa 4,8 3 1,4 0,1 setosa 5 3,2 1,2 0,2 setosa 4,6 3,4 1,4 0,3 setosa 4,6 3,2 1,4 0,2 setosa 4,7 3,2 1,3 0,2 setosa 4,4 2,9 1,4 0,2 setosa 4,5 2,3 1,3 0,3 setosa 4,4 3 1,3 0,2 setosa 4,4 3,2 1,3 0,2 setosa 4,6 3,6 1 0,2 setosa 4,3 3 1,1 0,1 setosa Menghitung jarak dengan sample data : (A-S1)^2 (B-S2)^2 (C-S3)^2 (D-S4)^2 SQRT(D) 8,4 0,2 0,8 0,4 3,1 7,3 0,3 0,6 0,0 2,9 8,4 0,2 0,5 0,0 3,0 7,3 0,3 1,0 0,4 3,0 7,3 0,2 0,3 0,0 2,8 6,3 0,1 0,8 0,1 2,7 8,4 0,2 1,4 0,2 3,2 9,0 0,1 0,3 0,1 3,1 6,3 0,3 1,0 0,1 2,8 7,8 0,5 0,4 0,1 3,0 7,8 0,3 1,7 0,2 3,2 6,3 0,5 0,2 0,0 2,6 7,3 0,2 0,0 0,1 2,8 5,3 0,6 0,5 0,0 2,5 6,8 0,3 0,0 0,1 2,7 6,8 0,4 0,2 0,2 2,7 5,8 0,6 1,2 0,0 2,8 4,8 0,5 0,4 0,0 2,4 5,8 0,1 0,1 0,0 2,4 5,8 0,1 1,2 0,4 2,7 5,3 0,0 0,3 0,0 2,4 6,3 0,3 1,7 0,0 2,9 5,3 1,0 0,6 0,0 2,6 4,4 0,3 0,5 0,0 2,3 5,3 0,5 0,8 0,0 2,6 7,3 0,2 2,0 0,5 3,1 5,8 0,2 1,7 0,0 2,8 8,4 0,1 2,3 0,4 3,3 5,3 1,0 0,5 0,0 2,6 7,3 0,0 2,3 0,2 3,1 4,0 0,3 0,4 0,0 2,1 5,8 0,5 2,0 0,2 2,9 5,8 0,5 2,0 0,3 2,9 5,8 0,4 0,0 0,2 2,5 5,3 0,4 2,0 0,0 2,8 4,4 0,4 0,3 0,1 2,3 10,2 0,3 2,6 0,0 3,6 4,4 0,3 0,2 0,1 2,2 9,6 0,3 2,9 0,2 3,6 7,3 0,0 2,3 0,6 3,2 4,8 0,0 1,4 0,4 2,6 3,6 0,1 0,4 0,0 2,0 6,3 0,3 2,6 0,3 3,1 3,6 0,3 0,8 0,0 2,2 4,0 0,6 0,8 0,0 2,3 4,0 0,4 0,1 0,0 2,1 7,3 1,0 2,6 0,0 3,3 7,8 0,1 2,9 0,4 3,3 4,8 0,4 0,0 0,2 2,3 4,0 0,0 0,1 0,0 2,0 5,3 0,0 2,0 0,5 2,8 4,4 0,5 0,3 0,3 2,3 10,2 0,1 3,2 0,0 3,7 4,8 1,7 0,1 0,0 2,6 5,3 1,4 0,0 0,2 2,6 3,2 0,6 0,8 0,0 2,2 3,2 0,6 0,8 0,0 2,2 3,2 0,5 0,8 0,5 2,2 3,6 0,3 0,0 0,0 2,0 11,6 0,5 3,6 0,0 4,0 4,0 1,7 0,6 0,0 2,5 4,4 0,8 2,0 0,1 2,7 2,9 1,0 0,6 0,1 2,1 4,4 0,5 0,0 0,2 2,3 2,6 0,5 0,5 0,1 1,9 13,7 0,3 3,6 0,4 4,2 5,3 0,0 3,2 0,6 3,0 2,6 0,3 0,1 0,0 1,7 2,9 0,5 0,1 0,2 1,9 10,2 0,0 3,6 0,6 3,8 10,9 0,4 4,4 0,0 4,0 2,9 0,4 0,0 0,2 1,8 2,9 0,3 0,0 0,3 1,8 2,9 0,5 0,0 0,2 1,9 3,2 0,8 0,0 0,3 2,1 2,0 0,3 0,1 0,0 1,5 2,6 0,6 0,0 0,2 1,8 2,6 0,3 0,0 0,2 1,7 3,2 0,6 0,1 0,3 2,1 3,2 0,6 0,0 0,5 2,1 2,3 0,8 0,0 0,3 1,8 4,0 1,7 0,0 0,5 2,5 13,0 0,3 5,8 0,2 4,4 2,3 1,0 0,0 0,2 1,9 2,6 1,0 0,1 0,4 2,0 2,3 1,4 0,0 0,2 2,0 2,6 0,4 0,4 0,2 1,9 15,2 0,1 4,8 0,1 4,5 13,7 0,5 6,3 0,1 4,5 2,3 1,2 0,2 0,4 2,0 1,4 0,6 0,1 0,1 1,5 2,9 0,8 0,5 0,5 2,2 13,7 0,1 6,3 0,3 4,5 2,3 1,2 0,3 0,5 2,0 0,8 1,0 0,1 0,0 1,4 13,7 0,8 7,3 0,4 4,7 1,0 2,3 0,5 0,5 2,1 1,0 1,4 0,8 0,5 1,9 1,2 1,0 1,4 0,4 2,0 0,8 1,2 0,8 0,5 1,8 2,9 0,1 6,3 2,0 3,3 1,2 0,1 5,3 1,7 2,9 2,0 0,2 6,3 1,7 3,2 1,2 0,0 6,3 1,4 3,0 2,0 0,0 6,3 2,3 3,2 2,0 0,0 7,3 1,7 3,3 1,0 0,0 6,8 1,2 3,0 0,6 0,0 5,3 2,3 2,9 1,0 0,0 6,8 1,7 3,1 2,9 0,8 7,3 1,7 3,6 2,0 0,0 7,3 2,3 3,4 1,0 0,3 6,8 2,3 3,2 1,7 0,0 7,3 2,3 3,4 1,2 0,0 7,3 1,7 3,2 1,4 0,0 7,3 2,3 3,3 1,2 0,1 6,8 2,3 3,2 1,2 0,0 7,3 2,3 3,3 2,3 0,0 8,4 2,3 3,6 1,2 0,1 7,3 2,0 3,2 2,0 0,2 8,4 1,7 3,5 1,4 0,0 7,8 2,3 3,4 1,0 0,0 7,3 2,3 3,2 1,2 0,0 7,8 2,0 3,3 0,6 0,2 6,8 2,3 3,1 0,6 0,0 6,8 2,3 3,1 2,3 0,5 7,8 2,3 3,6 3,2 0,3 9,0 2,3 3,8 1,2 0,0 7,8 2,3 3,4 0,5 0,1 6,8 2,3 3,1 1,0 0,0 7,8 2,3 3,3 0,8 0,2 7,3 2,6 3,3 0,8 0,2 7,3 2,6 3,3 0,8 0,2 7,3 2,6 3,3 1,4 0,4 7,3 2,6 3,4 1,0 0,0 7,8 2,3 3,3 0,8 0,3 7,8 2,3 3,3 0,6 0,3 7,8 2,0 3,3 1,0 0,0 8,4 2,0 3,4 0,4 0,2 7,3 2,3 3,2 0,6 0,3 7,8 2,6 3,4 1,0 0,1 9,0 2,3 3,5 0,4 0,0 7,8 2,0 3,2 0,4 0,1 7,8 2,3 3,2 0,5 0,1 8,4 2,3 3,4 0,2 0,4 7,8 2,3 3,3 0,3 1,4 8,4 2,0 3,5 0,2 0,3 8,4 2,3 3,3 0,2 0,1 8,4 2,3 3,3 0,4 0,0 10,2 2,3 3,6 0,1 0,3 9,6 2,6 3,5 Mencari data tertinggi K = 5: sepal_length as A sepal_width as B petal_length as C petal_width as D species (A-S1)^2 (B-S2)^2 (C-S3)^2 (D-S4)^2 SQRT(D) 5,6 3 4,5 1,5 versicolor 2,6 0,3 0,1 0,0 1,7 5,4 3 4,5 1,5 versicolor 2,0 0,3 0,1 0,0 1,5 5,6 3 4,1 1,3 versicolor 2,6 0,3 0,0 0,2 1,7 5,2 2,7 3,9 1,4 versicolor 1,4 0,6 0,1 0,1 1,5 4,9 2,5 4,5 1,7 virginica 0,8 1,0 0,1 0,0 1,4 Menghitung berat antar variasi dengan 1/jaraknya : D 1/D Setosa versicolor virginica 1,4 0,725476 0 0 0,725476 1,5 0,65372 0 0,65372 0 1,5 0,66519 0 0,66519 0 1,7 0,583212 0 0,583212 0 1,7 0,579284 0 0,579284 0 sum 0 2,481407 0,725476 Jadi Nilai terbesar adalah : class = versicolor","title":"W-KNN (Weighted K-Nearest Neighbour)"},{"location":"tugas1/","text":"Pengertian \u00b6 Statistika deskriptif adalah metode-metode yang berkaitan dengan pengumpulan dan penyajian suatu gugus data sehingga memberikan informasi yang berguna. Pengklasifikasian menjadi statistika deskriptif dan statistika inferensi dilakukan berdasarkan aktivitas yang dilakukan. Statistika deskriptif hanya memberikan informasi mengenai data yang dipunyai dan sama sekali tidak menarik inferensia atau kesimpulan apapun tentang gugus induknya yang lebih besar. Contoh statistika deskriptif yang sering muncul adalah, tabel, diagram, grafik, dan besaran-besaran lain di majalah dan koran-koran Dengan Statistika deskriptif, kumpulan data yang diperoleh akan tersaji dengan ringkas dan rapi serta dapat memberikan informasi inti dari kumpulan data yang ada. Informasi yang dapat diperoleh dari statistika deskriptif ini antara lain: ukuran pemusatan data, ukuran penyebaran data serta kecenderungan suatu gugus data. Tipe Statistik Deskriptif \u00b6 Mean (rata-rata) \u00b6 Mean adalah *nilai rata-rata* dari beberapa buah data. Nilai mean dapat ditentukan dengan membagi jumlah data dengan banyaknya data. Mean (rata-rata) merupakan suatu ukuran pemusatan data. Mean suatu data juga merupakan statistik karena mampu menggambarkan bahwa data tersebut berada pada kisaran mean data tersebut. Mean tidak dapat digunakan sebagai ukuran pemusatan untuk jenis data nominal dan ordinal. Berdasarkan definisi dari mean adalah jumlah seluruh data dibagi dengan banyaknya data. Dengan kata lain jika kita memiliki N data sebagai berikut maka mean data tersebut dapat kita tuliskan sebagai berikut : $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Dimana: x = data ke n x bar = x rata-rata = nilai rata-rata sampel n = banyaknya data Median \u00b6 Median menentukan letak tengah data setelah data disusun menurut urutan nilainya. Bisa juga *nilai tengah dari data-data yang terurut. Simbol untuk median adalah Me. Dengan median Me, maka 50% dari banyak data nilainya paling tinggi sama dengan Me, dan 50% dari banyak data nilainya paling rendah sama dengan Me. Dalam mencari median, dibedakan untuk banyak data ganjil dan banyak data genap. Untuk banyak data ganjil, setelah data disusun menurut nilainya, maka median Me adalah data yang terletak tepat di tengah. Median bisa dihitung menggunakan rumus sebagai berikut: $$ Me=Q_2 =\\left( \\begin{matrix} ^xn+1 \\over 2 \\end{matrix} \\right), jika n ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {^xn \\over 2 } {^xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika n genap $$ Modus \u00b6 Modus adalah nilai yang sering muncul. Jika kita tertarik pada data frekuensi, jumlah dari suatu nilai dari kumpulan data, maka kita menggunakan modus. Modus sangat baik bila digunakan untuk data yang memiliki sekala kategorik yaitu nominal atau ordinal. Modus bisa dihitung menggunakan rumus sebagai berikut: $$ M_o = L + i{b_i \\over b_1 + b_2} $$ Dimana: Mo = Modus L = Tepi bawah kelas yang memiliki frekuensi tertinggi (kelas modus) i = Interval kelas b1 = Frekuensi kelas modus dikurangi frekuensi kelas interval terdekat sebelumnya b2 = frekuensi kelas modus dikurangi frekuensi kelas interval terdekat sesudahnya Standar Deviasi \u00b6 Standar Deviasi dan Varians Salah satu teknik statistik yg digunakan untuk menjelaskan homogenitas kelompok. Varians merupakan jumlah kuadrat semua deviasi nilai-nilai individual terhadap rata-rata kelompok. Sedangkan akar dari varians disebut dengan standar deviasi atau simpangan baku. Standar Deviasi dan Varians Simpangan baku merupakan variasi sebaran data. Semakin kecil nilai sebarannya berarti variasi nilai data makin sama Jika sebarannya bernilai 0, maka nilai semua datanya adalah sama. Semakin besar nilai sebarannya berarti data semakin bervariasi. Standar Deviasi bisa didapat menggunakan rumus sebagai berikut: $$ \\sigma = {\\sqrt{ \\sum \\limits_{i=1}^{n} {(x_1-\\bar x)^2 } \\over n }} $$ Dimana : x = data ke n x bar = x rata-rata = nilai rata-rata sampel n = banyaknya data Varians \u00b6 Varians merupakan rata-rata dari selisih kuadrat tersebut merupakan suatu ukuran penyimpangan dari observasi. Simbol varians pada ukuran populasi sigma kuarat dan pada ukuran sample S2. Akar dari varians dinamakan standar deviasi atau simpangan baku. Varians bisa didapat menggunakan rumus sebagai berikut: $$ S^2 = {\\sqrt{ \\sum \\limits_{i=1}^{n} {(x_1-\\bar x)^2 } \\over n-1 }} $$ Skewness \u00b6 Skewness ( kemencengan ) adalah derajat ketidaksimetrisan suatu distribusi. Jika kurva frekuensi suatu distribusi memiliki ekor yang lebih memanjang ke kanan (dilihat dari meannya) maka dikatakan menceng kanan (positif) dan jika sebaliknya maka menceng kiri (negatif). Secara perhitungan, skewness adalah momen ketiga terhadap mean. Distribusi normal (dan distribusi simetris lainnya, misalnya distribusi t atau Cauchy) memiliki skewness 0 (nol). Skewness bisa dihitung menggunakan rumus sebagai berikut: $$ Skewness (S) = {{1 \\over T\\sigma^3} \\sum \\limits_{i=1}^{n}(r_2 - \\mu)^3} $$ Quartile \u00b6 Quartile adalah nilai-nilai yang membagi segugus pengamatan menjadi empat bagian sama besar. Nilai-nilai itu, yang dilambangkan dengan Q1, Q2, dan Q3, mempunyai sifat bahwa 25% data jatuh dibawah Q1, 50% data jatuh dibawah Q2, dan 75% data jatuh dibawah Q3. Quartile bisa dihitung menggunakan rumus sebagai berikut: $$ Q_1 = {x_{{1\\over4}(n+1)}} $$ $$ Q_2 = {x_{{1\\over2}(n+1)}} $$ $$ Q_3 = {x_{{3\\over4}(n+1)}} $$ Penerapan statistik deskriptif menggunakan python \u00b6 Alat dan Bahan \u00b6 Pada penerapan ini saya menggunakan 500 data random yang disimpan dalam bentuk .csv dan untuk mempermudah dalam penerapan tersebut, perlu disiapkan library python yang dapat didownload secara gratis. dalam kasus ini library python yang digunakan adalah sebagai berikut: pandas, digunakan untuk data manajemen dan data analysis. scipy, berisi kumpulan algoritme dan fungsi matematika. Pertama \u00b6 pada langkah ini kita memasukkan library yang telah disiapkan sebelumya import pandas as pd from scipy import stats Kedua \u00b6 dan selanjutnya memuat data csv yang telah disiapkan df = pd . read_csv ( 'Data.csv' , sep = ';' ) Ketiga \u00b6 kemudian membuat data penyimpanan ( dictionary ) yang menampung nilai yang akan ditampilkan. selanjutnya mengambil data dari beberapa kolom pada csv dengan cara diiterasi serta menghitungnya dengan berbagai metode yang telah disiapkan oleh pandas itu sendiri. kemudian hasil tersebut di disimpan pada penyimpanan tadi data = { \"Stats\" : [ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] Keempat \u00b6 terakhir adalah menvisualisasikan hasil tersebut dalam bentuk dataframe tes = pd . DataFrame ( data ) tes . style . hide_index () stats data 1 data 2 data 3 data 4 Min 81 81 80 80 Max 160 160 160 160 Mean 120.26 124.67 122 118.02 Standard Deviasi 24.78 22.47 24.55 22.67 Variasi 613.89 504.89 602.57 513.72 Skewnes 0.11 -0.22 -0.07 0.12 Quantile 1 97 106.75 101.75 99.5 Quantile 2 117.5 126.5 123.5 118 Quantile 3 143.25 143.25 144 137.25 Median 117.5 126.5 123.5 118 Modus 84 131 89 124 Referensi http://blog.ub.ac.id/adiarsa/2012/03/14/mean-median-modus-dan-standar-deviasi/ http://statutorial.blogspot.com/2008/01/skewness-dan-kurtosis.html https://www.rumusstatistik.com/2013/07/varian-dan-standar-deviasi-simpangan.html https://www.rumusstatistik.com/2016/12/membuat-rumus-matematika-dengan-latex.html https://englishccit.wordpress.com/2012/03/27/pengertian-statistik-deskriptif/#more-1194 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} }); MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Stastistik Deskriptif"},{"location":"tugas1/#pengertian","text":"Statistika deskriptif adalah metode-metode yang berkaitan dengan pengumpulan dan penyajian suatu gugus data sehingga memberikan informasi yang berguna. Pengklasifikasian menjadi statistika deskriptif dan statistika inferensi dilakukan berdasarkan aktivitas yang dilakukan. Statistika deskriptif hanya memberikan informasi mengenai data yang dipunyai dan sama sekali tidak menarik inferensia atau kesimpulan apapun tentang gugus induknya yang lebih besar. Contoh statistika deskriptif yang sering muncul adalah, tabel, diagram, grafik, dan besaran-besaran lain di majalah dan koran-koran Dengan Statistika deskriptif, kumpulan data yang diperoleh akan tersaji dengan ringkas dan rapi serta dapat memberikan informasi inti dari kumpulan data yang ada. Informasi yang dapat diperoleh dari statistika deskriptif ini antara lain: ukuran pemusatan data, ukuran penyebaran data serta kecenderungan suatu gugus data.","title":"Pengertian"},{"location":"tugas1/#tipe-statistik-deskriptif","text":"","title":"Tipe Statistik Deskriptif"},{"location":"tugas1/#mean-rata-rata","text":"Mean adalah *nilai rata-rata* dari beberapa buah data. Nilai mean dapat ditentukan dengan membagi jumlah data dengan banyaknya data. Mean (rata-rata) merupakan suatu ukuran pemusatan data. Mean suatu data juga merupakan statistik karena mampu menggambarkan bahwa data tersebut berada pada kisaran mean data tersebut. Mean tidak dapat digunakan sebagai ukuran pemusatan untuk jenis data nominal dan ordinal. Berdasarkan definisi dari mean adalah jumlah seluruh data dibagi dengan banyaknya data. Dengan kata lain jika kita memiliki N data sebagai berikut maka mean data tersebut dapat kita tuliskan sebagai berikut : $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Dimana: x = data ke n x bar = x rata-rata = nilai rata-rata sampel n = banyaknya data","title":"Mean (rata-rata)"},{"location":"tugas1/#median","text":"Median menentukan letak tengah data setelah data disusun menurut urutan nilainya. Bisa juga *nilai tengah dari data-data yang terurut. Simbol untuk median adalah Me. Dengan median Me, maka 50% dari banyak data nilainya paling tinggi sama dengan Me, dan 50% dari banyak data nilainya paling rendah sama dengan Me. Dalam mencari median, dibedakan untuk banyak data ganjil dan banyak data genap. Untuk banyak data ganjil, setelah data disusun menurut nilainya, maka median Me adalah data yang terletak tepat di tengah. Median bisa dihitung menggunakan rumus sebagai berikut: $$ Me=Q_2 =\\left( \\begin{matrix} ^xn+1 \\over 2 \\end{matrix} \\right), jika n ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {^xn \\over 2 } {^xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika n genap $$","title":"Median"},{"location":"tugas1/#modus","text":"Modus adalah nilai yang sering muncul. Jika kita tertarik pada data frekuensi, jumlah dari suatu nilai dari kumpulan data, maka kita menggunakan modus. Modus sangat baik bila digunakan untuk data yang memiliki sekala kategorik yaitu nominal atau ordinal. Modus bisa dihitung menggunakan rumus sebagai berikut: $$ M_o = L + i{b_i \\over b_1 + b_2} $$ Dimana: Mo = Modus L = Tepi bawah kelas yang memiliki frekuensi tertinggi (kelas modus) i = Interval kelas b1 = Frekuensi kelas modus dikurangi frekuensi kelas interval terdekat sebelumnya b2 = frekuensi kelas modus dikurangi frekuensi kelas interval terdekat sesudahnya","title":"Modus"},{"location":"tugas1/#standar-deviasi","text":"Standar Deviasi dan Varians Salah satu teknik statistik yg digunakan untuk menjelaskan homogenitas kelompok. Varians merupakan jumlah kuadrat semua deviasi nilai-nilai individual terhadap rata-rata kelompok. Sedangkan akar dari varians disebut dengan standar deviasi atau simpangan baku. Standar Deviasi dan Varians Simpangan baku merupakan variasi sebaran data. Semakin kecil nilai sebarannya berarti variasi nilai data makin sama Jika sebarannya bernilai 0, maka nilai semua datanya adalah sama. Semakin besar nilai sebarannya berarti data semakin bervariasi. Standar Deviasi bisa didapat menggunakan rumus sebagai berikut: $$ \\sigma = {\\sqrt{ \\sum \\limits_{i=1}^{n} {(x_1-\\bar x)^2 } \\over n }} $$ Dimana : x = data ke n x bar = x rata-rata = nilai rata-rata sampel n = banyaknya data","title":"Standar Deviasi"},{"location":"tugas1/#varians","text":"Varians merupakan rata-rata dari selisih kuadrat tersebut merupakan suatu ukuran penyimpangan dari observasi. Simbol varians pada ukuran populasi sigma kuarat dan pada ukuran sample S2. Akar dari varians dinamakan standar deviasi atau simpangan baku. Varians bisa didapat menggunakan rumus sebagai berikut: $$ S^2 = {\\sqrt{ \\sum \\limits_{i=1}^{n} {(x_1-\\bar x)^2 } \\over n-1 }} $$","title":"Varians"},{"location":"tugas1/#skewness","text":"Skewness ( kemencengan ) adalah derajat ketidaksimetrisan suatu distribusi. Jika kurva frekuensi suatu distribusi memiliki ekor yang lebih memanjang ke kanan (dilihat dari meannya) maka dikatakan menceng kanan (positif) dan jika sebaliknya maka menceng kiri (negatif). Secara perhitungan, skewness adalah momen ketiga terhadap mean. Distribusi normal (dan distribusi simetris lainnya, misalnya distribusi t atau Cauchy) memiliki skewness 0 (nol). Skewness bisa dihitung menggunakan rumus sebagai berikut: $$ Skewness (S) = {{1 \\over T\\sigma^3} \\sum \\limits_{i=1}^{n}(r_2 - \\mu)^3} $$","title":"Skewness"},{"location":"tugas1/#quartile","text":"Quartile adalah nilai-nilai yang membagi segugus pengamatan menjadi empat bagian sama besar. Nilai-nilai itu, yang dilambangkan dengan Q1, Q2, dan Q3, mempunyai sifat bahwa 25% data jatuh dibawah Q1, 50% data jatuh dibawah Q2, dan 75% data jatuh dibawah Q3. Quartile bisa dihitung menggunakan rumus sebagai berikut: $$ Q_1 = {x_{{1\\over4}(n+1)}} $$ $$ Q_2 = {x_{{1\\over2}(n+1)}} $$ $$ Q_3 = {x_{{3\\over4}(n+1)}} $$","title":"Quartile"},{"location":"tugas1/#penerapan-statistik-deskriptif-menggunakan-python","text":"","title":"Penerapan statistik deskriptif menggunakan python"},{"location":"tugas1/#alat-dan-bahan","text":"Pada penerapan ini saya menggunakan 500 data random yang disimpan dalam bentuk .csv dan untuk mempermudah dalam penerapan tersebut, perlu disiapkan library python yang dapat didownload secara gratis. dalam kasus ini library python yang digunakan adalah sebagai berikut: pandas, digunakan untuk data manajemen dan data analysis. scipy, berisi kumpulan algoritme dan fungsi matematika.","title":"Alat dan Bahan"},{"location":"tugas1/#pertama","text":"pada langkah ini kita memasukkan library yang telah disiapkan sebelumya import pandas as pd from scipy import stats","title":"Pertama"},{"location":"tugas1/#kedua","text":"dan selanjutnya memuat data csv yang telah disiapkan df = pd . read_csv ( 'Data.csv' , sep = ';' )","title":"Kedua"},{"location":"tugas1/#ketiga","text":"kemudian membuat data penyimpanan ( dictionary ) yang menampung nilai yang akan ditampilkan. selanjutnya mengambil data dari beberapa kolom pada csv dengan cara diiterasi serta menghitungnya dengan berbagai metode yang telah disiapkan oleh pandas itu sendiri. kemudian hasil tersebut di disimpan pada penyimpanan tadi data = { \"Stats\" : [ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]]","title":"Ketiga"},{"location":"tugas1/#keempat","text":"terakhir adalah menvisualisasikan hasil tersebut dalam bentuk dataframe tes = pd . DataFrame ( data ) tes . style . hide_index () stats data 1 data 2 data 3 data 4 Min 81 81 80 80 Max 160 160 160 160 Mean 120.26 124.67 122 118.02 Standard Deviasi 24.78 22.47 24.55 22.67 Variasi 613.89 504.89 602.57 513.72 Skewnes 0.11 -0.22 -0.07 0.12 Quantile 1 97 106.75 101.75 99.5 Quantile 2 117.5 126.5 123.5 118 Quantile 3 143.25 143.25 144 137.25 Median 117.5 126.5 123.5 118 Modus 84 131 89 124 Referensi http://blog.ub.ac.id/adiarsa/2012/03/14/mean-median-modus-dan-standar-deviasi/ http://statutorial.blogspot.com/2008/01/skewness-dan-kurtosis.html https://www.rumusstatistik.com/2013/07/varian-dan-standar-deviasi-simpangan.html https://www.rumusstatistik.com/2016/12/membuat-rumus-matematika-dengan-latex.html https://englishccit.wordpress.com/2012/03/27/pengertian-statistik-deskriptif/#more-1194 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} }); MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Keempat"},{"location":"tugas2/","text":"Missing Values \u00b6 Missing Values atau data hilang yaitu informasi yang tidak tersedia untuk sebuah objek(kasus). Missing Values terjadi karena informasi tidak diberikan atau hilang atau bahkan tidak ada sama sekali. Metode untuk mengatasi Missing Values \u00b6 1. Prosedur berbasis unit yang lengkap (completely recorded units) \u00b6 Pada prosedur ini analisis hanya dilakukan terhadap unit (sebanyak n1 case , baris pada matriks data n x m) dimana seluruh m variabel memiliki data yang lengkap sedangkan sebanyak n2 case yang ada missing value pada variabelnya diabaikan atau dikeluarkan dari analisis metode ini cukup bagus jika jumlah missing values tidak terlalu besar, tapi akan menjad tidak efisien jika presentasi missing data (n2/n).100 meningkat atau missing value mengelompok. 2. Prosedur berbasis imputasi \u00b6 imputasi adalah alternatif yang umum dan fleksibel. dengan metode ini missing value diisi dengan menduga langsung atau juga dengan menduga berbasis korelasi. terdapat bebrapa macam pendekatan untuk imputasi ini, antara lain : a. Hot deck imputation, dimana dari unit yang tercatat akan disubstitusikan terhadap missing values b . cold deck imputation, dimana missing value diganti oleh suatu nilai yang konstan c. mean imputation, nilai yang hilang diganti dengan rata-rata(mean) dari kelompok satu unit yang terkait d. regression (corelation) imputation, missing value dari suatu variabel diestimasi menggunakan nilai penduga dari regresi atau korelasi variabel tersebut pada variabel lainnya 3. prosedur weigthing \u00b6 weighting yaitu dimana estimasi biasanya didasarkan pada design weight, yaitu proporsional secara terbalik terhadap peluang pemilihan sampelnya 4. Prosedur berbasis Model \u00b6 prosedur ini dibentuk dengan menentukan suatu model sebagian data hilang (missing values) lalu melakukan inferensi berbasis pada likelihood dibawah model tersebut. parameter diestimasi dengan suatu prosedur iteratif maximum likelihood dimaulai dengan unit atau cases yang lengkap 5. metode K-Nearest Neighbor (KNN) \u00b6 K-Nearest Neighbor atau biasa disingkat KNN adalah suatu algoritma yang digunakan untuk mengklasifikasi objek berdasar dari data pembelajaran yang jaraknya paling dekat dengan objek tersebut. disini saya memberi contoh menggunakan data yang bisa didownload Disini 3365 10050 8 ? ? ? 211.9188 0.019817 0.000633 4 0.000201 0.000201 0.003912 31.8222 54.5588 5.0294 14 0.001409 3 0.000000 0.000000 3366 10051 8 ? ? ? 269.8998 0.024645 0.000642 10 0.000415 0.000491 0.004015 25.6352 43.3856 6.4922 21 0.000478 6 0.000000 0.000579 3367 10052 8 ? ? ? 190.2396 0.008720 0.000879 10 0.000171 0.000342 0.004971 17.9901 35.9509 5.5872 21 0.000904 5 0.000000 0.000000 3368 10055 8 ? ? ? 212.4972 0.014917 0.000767 10 0.000599 0.000273 0.005648 21.6687 41.2231 4.4680 28 0.001119 9 0.000035 0.000062 3369 10059 8 ? ? ? 219.3894 0.005926 0.000741 6 0.000440 0.000709 0.005185 17.0456 30.5342 6.6749 35 0.002072 9 0.000225 0.000064 3370 10060 8 ? ? ? 230.6694 0.010383 0.001242 10 0.000375 0.003328 0.006375 13.5028 31.4044 5.0533 32 0.001512 6 0.000035 0.000047 3371 10061 8 ? ? ? 284.2296 0.016069 0.000711 9 0.000355 0.000548 0.006680 9.4756 29.6851 5.3326 25 0.002459 7 0.000000 0.000000 3372 10062 8 ? ? ? 355.3518 0.037526 0.000600 7 0.001242 0.000514 0.004541 9.2871 41.9497 6.5063 22 0.001228 8 0.000000 0.000614 3373 10063 8 ? ? ? 364.8504 0.042576 0.000996 8 0.000176 0.000146 0.004687 19.9499 41.1417 5.6167 18 0.000674 7 0.000000 0.000000 3374 10064 8 ? ? ? 256.5888 0.019592 0.000580 8 0.000416 0.000357 0.005812 17.0462 34.3734 5.0563 19 0.001308 7 0.000000 0.000000 3375 10065 8 ? ? ? 248.4012 0.016018 0.000874 9 0.000388 0.000372 0.005987 16.3144 30.2486 5.0973 21 0.001197 6 0.000000 0.000000 3376 10066 8 ? ? ? 251.2284 0.022910 0.000946 5 0.001097 0.001173 0.005411 13.7404 35.7203 4.5524 22 0.000738 5 0.000000 0.000662 3377 10067 8 ? ? ? 318.3000 0.034851 0.000933 7 0.000187 0.000023 0.005225 26.0987 32.4464 4.8705 13 0.000933 4 0.000000 0.000233 3378 10068 8 ? ? ? 288.9198 0.029322 0.001569 6 0.000118 0.000219 0.005213 23.2857 32.8026 4.7540 24 0.001130 5 0.000000 0.000000 3379 10069 8 ? ? ? 313.9080 0.019537 0.001214 4 0.000318 0.000607 0.005879 8.1642 26.0918 6.7885 26 0.001321 8 0.000106 0.000443 3380 10072 8 ? ? ? 243.7134 0.017195 0.000711 6 0.000666 0.000426 0.005594 21.8795 30.5722 5.1136 25 0.000576 8 0.000000 0.000000 3381 10073 8 ? ? ? 312.9804 0.026327 0.000266 6 0.000000 0.000207 0.005053 14.6118 30.7836 6.1930 10 0.001802 4 0.000000 0.000030 3382 10074 8 ? ? ? 313.5762 0.030550 0.000560 5 0.000000 0.000206 0.004390 19.5405 35.4094 6.4228 12 0.001296 3 0.000000 0.000059 3383 10075 8 ? ? ? 274.6194 0.022497 0.000707 6 0.000163 0.000082 0.004053 20.6757 32.7785 6.9262 15 0.000626 3 0.000000 0.000000 3384 10076 8 ? ? ? 225.0678 0.014339 0.001627 7 0.000291 0.000911 0.005281 16.3502 33.2874 5.4713 26 0.000898 8 0.000000 0.000959 3385 10079 8 ? ? ? 254.2188 0.016608 0.000788 6 0.000926 0.000330 0.005408 14.9191 35.9921 5.7205 28 0.001128 6 0.000000 0.000000 3386 10081 8 ? ? ? 339.1524 0.033058 0.001017 10 0.000477 0.000509 0.004609 21.6389 37.1862 6.7103 16 0.001049 3 0.000000 0.000000 3387 10082 8 ? ? ? 310.0416 0.026873 0.001278 10 0.000319 0.000479 0.005517 16.5446 33.8174 5.7350 22 0.000922 8 0.000000 0.000000 3388 10083 8 ? ? ? 288.7608 0.024022 0.000628 6 0.000350 0.001051 0.005580 19.0108 30.0866 5.3831 30 0.000761 5 0.000000 0.000652 3389 10084 8 ? ? ? 151.4046 0.009732 0.000949 6 0.000028 0.000156 0.004363 27.4658 43.8052 4.3312 23 0.000949 6 0.000000 0.000099 3390 10089 8 ? ? ? 259.6296 0.020425 0.000743 9 0.000621 0.000146 0.004555 18.6059 42.8342 6.2754 46 0.000877 5 0.000000 0.000000 3391 10090 8 ? ? ? 314.6700 0.028043 0.001157 10 0.000246 0.001083 0.004259 14.3023 36.1156 7.1965 16 0.000788 4 0.000000 0.000000 3392 10092 8 ? ? ? 299.4282 0.028341 0.000860 7 0.000338 0.000169 0.004439 12.4028 39.5156 6.3979 19 0.001260 4 0.000000 0.000000 3393 10094 8 ? ? ? 375.8664 0.036436 0.000594 5 0.000204 0.000780 0.004346 11.6910 34.8547 7.9615 15 0.000613 6 0.000000 0.000631 3394 10095 8 ? ? ? 348.3576 0.029855 0.000811 4 0.000224 0.001315 0.005566 20.0537 33.5142 6.3719 27 0.001566 7 0.000457 0.000895 bisa dilihat dalam data tersebut terdapat banyak missing value dengan tanda ? pada anggota dari atributnya. Referensi \u00b6 https://statistikakomputasi.wordpress.com/2009/12/03/analisis-statistik-untuk-missing-data-introduction/ http://file.upi.edu/Direktori/FPIPS/LAINNYA/MEITRI_HENING/Modul/Modul_Analisis_Missing_Value_%26_Outlier.pdf","title":"Mising value"},{"location":"tugas2/#missing-values","text":"Missing Values atau data hilang yaitu informasi yang tidak tersedia untuk sebuah objek(kasus). Missing Values terjadi karena informasi tidak diberikan atau hilang atau bahkan tidak ada sama sekali.","title":"Missing Values"},{"location":"tugas2/#metode-untuk-mengatasi-missing-values","text":"","title":"Metode untuk mengatasi Missing Values"},{"location":"tugas2/#1-prosedur-berbasis-unit-yang-lengkap-completely-recorded-units","text":"Pada prosedur ini analisis hanya dilakukan terhadap unit (sebanyak n1 case , baris pada matriks data n x m) dimana seluruh m variabel memiliki data yang lengkap sedangkan sebanyak n2 case yang ada missing value pada variabelnya diabaikan atau dikeluarkan dari analisis metode ini cukup bagus jika jumlah missing values tidak terlalu besar, tapi akan menjad tidak efisien jika presentasi missing data (n2/n).100 meningkat atau missing value mengelompok.","title":"1. Prosedur berbasis unit yang lengkap (completely recorded units)"},{"location":"tugas2/#2-prosedur-berbasis-imputasi","text":"imputasi adalah alternatif yang umum dan fleksibel. dengan metode ini missing value diisi dengan menduga langsung atau juga dengan menduga berbasis korelasi. terdapat bebrapa macam pendekatan untuk imputasi ini, antara lain : a. Hot deck imputation, dimana dari unit yang tercatat akan disubstitusikan terhadap missing values b . cold deck imputation, dimana missing value diganti oleh suatu nilai yang konstan c. mean imputation, nilai yang hilang diganti dengan rata-rata(mean) dari kelompok satu unit yang terkait d. regression (corelation) imputation, missing value dari suatu variabel diestimasi menggunakan nilai penduga dari regresi atau korelasi variabel tersebut pada variabel lainnya","title":"2. Prosedur berbasis imputasi"},{"location":"tugas2/#3-prosedur-weigthing","text":"weighting yaitu dimana estimasi biasanya didasarkan pada design weight, yaitu proporsional secara terbalik terhadap peluang pemilihan sampelnya","title":"3. prosedur weigthing"},{"location":"tugas2/#4-prosedur-berbasis-model","text":"prosedur ini dibentuk dengan menentukan suatu model sebagian data hilang (missing values) lalu melakukan inferensi berbasis pada likelihood dibawah model tersebut. parameter diestimasi dengan suatu prosedur iteratif maximum likelihood dimaulai dengan unit atau cases yang lengkap","title":"4. Prosedur berbasis Model"},{"location":"tugas2/#5-metode-k-nearest-neighbor-knn","text":"K-Nearest Neighbor atau biasa disingkat KNN adalah suatu algoritma yang digunakan untuk mengklasifikasi objek berdasar dari data pembelajaran yang jaraknya paling dekat dengan objek tersebut. disini saya memberi contoh menggunakan data yang bisa didownload Disini 3365 10050 8 ? ? ? 211.9188 0.019817 0.000633 4 0.000201 0.000201 0.003912 31.8222 54.5588 5.0294 14 0.001409 3 0.000000 0.000000 3366 10051 8 ? ? ? 269.8998 0.024645 0.000642 10 0.000415 0.000491 0.004015 25.6352 43.3856 6.4922 21 0.000478 6 0.000000 0.000579 3367 10052 8 ? ? ? 190.2396 0.008720 0.000879 10 0.000171 0.000342 0.004971 17.9901 35.9509 5.5872 21 0.000904 5 0.000000 0.000000 3368 10055 8 ? ? ? 212.4972 0.014917 0.000767 10 0.000599 0.000273 0.005648 21.6687 41.2231 4.4680 28 0.001119 9 0.000035 0.000062 3369 10059 8 ? ? ? 219.3894 0.005926 0.000741 6 0.000440 0.000709 0.005185 17.0456 30.5342 6.6749 35 0.002072 9 0.000225 0.000064 3370 10060 8 ? ? ? 230.6694 0.010383 0.001242 10 0.000375 0.003328 0.006375 13.5028 31.4044 5.0533 32 0.001512 6 0.000035 0.000047 3371 10061 8 ? ? ? 284.2296 0.016069 0.000711 9 0.000355 0.000548 0.006680 9.4756 29.6851 5.3326 25 0.002459 7 0.000000 0.000000 3372 10062 8 ? ? ? 355.3518 0.037526 0.000600 7 0.001242 0.000514 0.004541 9.2871 41.9497 6.5063 22 0.001228 8 0.000000 0.000614 3373 10063 8 ? ? ? 364.8504 0.042576 0.000996 8 0.000176 0.000146 0.004687 19.9499 41.1417 5.6167 18 0.000674 7 0.000000 0.000000 3374 10064 8 ? ? ? 256.5888 0.019592 0.000580 8 0.000416 0.000357 0.005812 17.0462 34.3734 5.0563 19 0.001308 7 0.000000 0.000000 3375 10065 8 ? ? ? 248.4012 0.016018 0.000874 9 0.000388 0.000372 0.005987 16.3144 30.2486 5.0973 21 0.001197 6 0.000000 0.000000 3376 10066 8 ? ? ? 251.2284 0.022910 0.000946 5 0.001097 0.001173 0.005411 13.7404 35.7203 4.5524 22 0.000738 5 0.000000 0.000662 3377 10067 8 ? ? ? 318.3000 0.034851 0.000933 7 0.000187 0.000023 0.005225 26.0987 32.4464 4.8705 13 0.000933 4 0.000000 0.000233 3378 10068 8 ? ? ? 288.9198 0.029322 0.001569 6 0.000118 0.000219 0.005213 23.2857 32.8026 4.7540 24 0.001130 5 0.000000 0.000000 3379 10069 8 ? ? ? 313.9080 0.019537 0.001214 4 0.000318 0.000607 0.005879 8.1642 26.0918 6.7885 26 0.001321 8 0.000106 0.000443 3380 10072 8 ? ? ? 243.7134 0.017195 0.000711 6 0.000666 0.000426 0.005594 21.8795 30.5722 5.1136 25 0.000576 8 0.000000 0.000000 3381 10073 8 ? ? ? 312.9804 0.026327 0.000266 6 0.000000 0.000207 0.005053 14.6118 30.7836 6.1930 10 0.001802 4 0.000000 0.000030 3382 10074 8 ? ? ? 313.5762 0.030550 0.000560 5 0.000000 0.000206 0.004390 19.5405 35.4094 6.4228 12 0.001296 3 0.000000 0.000059 3383 10075 8 ? ? ? 274.6194 0.022497 0.000707 6 0.000163 0.000082 0.004053 20.6757 32.7785 6.9262 15 0.000626 3 0.000000 0.000000 3384 10076 8 ? ? ? 225.0678 0.014339 0.001627 7 0.000291 0.000911 0.005281 16.3502 33.2874 5.4713 26 0.000898 8 0.000000 0.000959 3385 10079 8 ? ? ? 254.2188 0.016608 0.000788 6 0.000926 0.000330 0.005408 14.9191 35.9921 5.7205 28 0.001128 6 0.000000 0.000000 3386 10081 8 ? ? ? 339.1524 0.033058 0.001017 10 0.000477 0.000509 0.004609 21.6389 37.1862 6.7103 16 0.001049 3 0.000000 0.000000 3387 10082 8 ? ? ? 310.0416 0.026873 0.001278 10 0.000319 0.000479 0.005517 16.5446 33.8174 5.7350 22 0.000922 8 0.000000 0.000000 3388 10083 8 ? ? ? 288.7608 0.024022 0.000628 6 0.000350 0.001051 0.005580 19.0108 30.0866 5.3831 30 0.000761 5 0.000000 0.000652 3389 10084 8 ? ? ? 151.4046 0.009732 0.000949 6 0.000028 0.000156 0.004363 27.4658 43.8052 4.3312 23 0.000949 6 0.000000 0.000099 3390 10089 8 ? ? ? 259.6296 0.020425 0.000743 9 0.000621 0.000146 0.004555 18.6059 42.8342 6.2754 46 0.000877 5 0.000000 0.000000 3391 10090 8 ? ? ? 314.6700 0.028043 0.001157 10 0.000246 0.001083 0.004259 14.3023 36.1156 7.1965 16 0.000788 4 0.000000 0.000000 3392 10092 8 ? ? ? 299.4282 0.028341 0.000860 7 0.000338 0.000169 0.004439 12.4028 39.5156 6.3979 19 0.001260 4 0.000000 0.000000 3393 10094 8 ? ? ? 375.8664 0.036436 0.000594 5 0.000204 0.000780 0.004346 11.6910 34.8547 7.9615 15 0.000613 6 0.000000 0.000631 3394 10095 8 ? ? ? 348.3576 0.029855 0.000811 4 0.000224 0.001315 0.005566 20.0537 33.5142 6.3719 27 0.001566 7 0.000457 0.000895 bisa dilihat dalam data tersebut terdapat banyak missing value dengan tanda ? pada anggota dari atributnya.","title":"5. metode K-Nearest Neighbor (KNN)"},{"location":"tugas2/#referensi","text":"https://statistikakomputasi.wordpress.com/2009/12/03/analisis-statistik-untuk-missing-data-introduction/ http://file.upi.edu/Direktori/FPIPS/LAINNYA/MEITRI_HENING/Modul/Modul_Analisis_Missing_Value_%26_Outlier.pdf","title":"Referensi"},{"location":"tugasku/","text":"tugasku","title":"Tugasku"}]}